{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extras \n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import LSTM, GRU, Dense, GlobalMaxPool1D, Embedding, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "y, X  = dmatrices('Spread ~  Dec_Residential_Mortgages + Dec_Commercial_Loans +Dec_Personal_Loans +  Dec_Financial_Lease + Dec_Financial_Investments + Dec_Other_Investments + Dec_Inventories + Dec_Intangible_Assets + Dec_Cash_Equivalent + Dec_Other_Receivables + Inc_Term_Deposit  + Inc_Demand_Deposit  + Inc_Broker_Deposit + Inc_Short_Borrow  + Inc_Long_Borrow  + Inc_NonInterest_Liabilities + Inc_Other_Payable', data, return_type = \"dataframe\")        \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "#Linear Regression\n",
    "linreg= LinearRegression()\n",
    "model_lin = linreg.fit(X_train, y_train)\n",
    "model_score = linreg.score(X_test, y_test)\n",
    "\n",
    "model_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Neural Networks\n",
    "# split into train and test sets\n",
    "train_X, train_y = data.iloc[:8000, :19], data.iloc[:8000,20:]\n",
    "test_X, test_y = data.iloc[8000:, :19], data.iloc[8000:,20:]\n",
    "# converting from dataframe to arrary \n",
    "test_X, test_y = test_X.values, test_y.values\n",
    "train_X, train_y = train_X.values, train_y.values\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Keras Sequential\n",
    "#design loss = binary_crossentropy, optimizer = adam ,  metrics= accuracy \n",
    "model_bc = Sequential()\n",
    "model_bc.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model_bc.add(Dense(1))\n",
    "model_bc.compile(loss='MSE', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# early stopping to prevent over-fitting\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0)\n",
    "\n",
    "\n",
    "# fit network\n",
    "history_bc = model_bc.fit(train_X, train_y, epochs=15, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False,  callbacks = [es] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Results of Binary Cross-Entropy with Adam Optimizer  \n",
    "print(\"Model Evaluation Accuracy of Binary Cross-Entropy\")\n",
    "print(model_bc.evaluate(test_X, test_y))\n",
    "print('Model Summary')\n",
    "model_bc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results Binary Cross-Entropy With Adam optimizer\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize= (8,3))\n",
    "plt.plot(history_bc.history['loss'], label='train')\n",
    "plt.plot(history_bc.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value Loss of Predictions')\n",
    "plt.title('Binary Cross-Entropy, Adam Optimizer')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results Binary Cross-Entropy With Adam optimizer\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize= (8,3))\n",
    "plt.plot(history_bc.history['acc'], label='train')\n",
    "plt.plot(history_bc.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Binary Cross-Entropy, Adam Optimizer')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs where extended to check for increased Accuracy\n",
    "# Model Design Binary Cross-Entropy, Adam Optimizer, Relu Activation \n",
    "model_SL = Sequential()\n",
    "model_SL.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model_SL.add(LSTM(50, activation='relu'))\n",
    "model_SL.add(Dense(64))\n",
    "model_SL.add(Dense(1))\n",
    "model_SL.compile(optimizer='adam', loss='MAE', metrics=['accuracy'])\n",
    "# early stopping to prevent over-fitting\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience = 5)\n",
    "\n",
    "# fit network\n",
    "history_SL = model_SL.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks= [es])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results MAE With Adam optimizer\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize= (8,3))\n",
    "plt.plot(history_SL.history['acc'], label='train')\n",
    "plt.plot(history_SL.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Mean Absolute Error, Adam Optimizer')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Results Binary Cross-Entropy With Adam optimizer\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize= (8,3))\n",
    "plt.plot(history_SL.history['loss'], label='train')\n",
    "plt.plot(history_SL.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value Loss of Predictions')\n",
    "plt.title('Binary Cross-Entropy, Adam Optimizer')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
